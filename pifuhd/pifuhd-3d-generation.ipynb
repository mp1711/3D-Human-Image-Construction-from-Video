{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11438993,"sourceType":"datasetVersion","datasetId":7165481}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/facebookresearch/pifuhd.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:08:23.714683Z","iopub.execute_input":"2025-04-16T19:08:23.715009Z","iopub.status.idle":"2025-04-16T19:08:24.496932Z","shell.execute_reply.started":"2025-04-16T19:08:23.714983Z","shell.execute_reply":"2025-04-16T19:08:24.496251Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'pifuhd'...\nremote: Enumerating objects: 222, done.\u001b[K\nremote: Counting objects: 100% (126/126), done.\u001b[K\nremote: Compressing objects: 100% (44/44), done.\u001b[K\nremote: Total 222 (delta 92), reused 82 (delta 82), pack-reused 96 (from 1)\u001b[K\nReceiving objects: 100% (222/222), 399.39 KiB | 12.10 MiB/s, done.\nResolving deltas: 100% (114/114), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/pifuhd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:06.917628Z","iopub.execute_input":"2025-04-16T19:46:06.918439Z","iopub.status.idle":"2025-04-16T19:46:06.923293Z","shell.execute_reply.started":"2025-04-16T19:46:06.918408Z","shell.execute_reply":"2025-04-16T19:46:06.922655Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/pifuhd\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:08:28.156818Z","iopub.execute_input":"2025-04-16T19:08:28.157656Z","iopub.status.idle":"2025-04-16T19:09:49.205444Z","shell.execute_reply.started":"2025-04-16T19:08:28.157629Z","shell.execute_reply":"2025-04-16T19:09:49.204727Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.5.1+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.20.1+cu124)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (11.1.0)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.25.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.67.1)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (4.11.0.86)\nCollecting trimesh (from -r requirements.txt (line 12))\n  Downloading trimesh-4.6.6-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: PyOpenGL in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.1.9)\nCollecting ffmpeg (from -r requirements.txt (line 14))\n  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 6))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 6))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 6))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 6))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 6))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 6))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 6))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 6)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 6)) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (1.15.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2025.1.10)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (24.2)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 7)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 7)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 7)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 7)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 7)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->-r requirements.txt (line 7)) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 6)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->-r requirements.txt (line 7)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->-r requirements.txt (line 7)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->-r requirements.txt (line 7)) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm0:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trimesh-4.6.6-py3-none-any.whl (709 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.3/709.3 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ffmpeg\n  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=314339e4d16b234878b488048edf6d5d6bde0d6d79cb5e48b53a79d11593ec59\n  Stored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\nSuccessfully built ffmpeg\nInstalling collected packages: ffmpeg, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trimesh\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ffmpeg-1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trimesh-4.6.6\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!sh ./scripts/download_trained_model.sh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:09:49.207329Z","iopub.execute_input":"2025-04-16T19:09:49.207837Z","iopub.status.idle":"2025-04-16T19:09:54.806799Z","shell.execute_reply.started":"2025-04-16T19:09:49.207813Z","shell.execute_reply":"2025-04-16T19:09:54.806080Z"}},"outputs":[{"name":"stdout","text":"+ mkdir -p checkpoints\n+ cd checkpoints\n+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n--2025-04-16 19:09:49--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.108, 3.163.189.96, 3.163.189.51, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.108|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1548375177 (1.4G) [application/octet-stream]\nSaving to: ‘pifuhd.pt’\n\npifuhd.pt           100%[===================>]   1.44G   289MB/s    in 5.4s    \n\n2025-04-16 19:09:54 (276 MB/s) - ‘pifuhd.pt’ saved [1548375177/1548375177]\n\n--2025-04-16 19:09:54--  http://pifuhd.pt/\nResolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\nwget: unable to resolve host address ‘pifuhd.pt’\nFINISHED --2025-04-16 19:09:54--\nTotal wall clock time: 5.5s\nDownloaded: 1 files, 1.4G in 5.4s (276 MB/s)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%rm -rf /kaggle/working/pifuhd/sample_images/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:10:03.682942Z","iopub.execute_input":"2025-04-16T19:10:03.683596Z","iopub.status.idle":"2025-04-16T19:10:03.802137Z","shell.execute_reply.started":"2025-04-16T19:10:03.683569Z","shell.execute_reply":"2025-04-16T19:10:03.801177Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"%cp /kaggle/input/data-for-testing-pix2pix-gan-with-pifuhd/images/female-1-casual-frame_0016_fake_B.png \\\n   /kaggle/input/data-for-testing-pix2pix-gan-with-pifuhd/images/female-1-casual-frame_0016_real_B.png \\\n   /kaggle/input/data-for-testing-pix2pix-gan-with-pifuhd/images/female-1-casual-frame_0075_fake_B.png \\\n   /kaggle/input/data-for-testing-pix2pix-gan-with-pifuhd/images/female-1-casual-frame_0075_real_B.png \\\n   /kaggle/working/pifuhd/sample_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:10:21.313040Z","iopub.execute_input":"2025-04-16T19:10:21.313812Z","iopub.status.idle":"2025-04-16T19:10:21.466373Z","shell.execute_reply.started":"2025-04-16T19:10:21.313777Z","shell.execute_reply":"2025-04-16T19:10:21.465598Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\n\nfilename = [f for f in os.listdir('/kaggle/working/pifuhd/sample_images') if f.endswith('.png')][3]\n\nimage_path = '/kaggle/working/pifuhd/sample_images/%s' % filename\n\nimage_dir = os.path.dirname(image_path)\nfile_name = os.path.splitext(os.path.basename(image_path))[1]\n\n# output paths\nobj_path = '/kaggle/working/pifuhd/results/pifuhd_final/recon/result_%s_256.obj' % file_name\nout_img_path = '/kaggle/working/pifuhd/results/pifuhd_final/recon/result_%s_256.png' % file_name\nvideo_path = '/kaggle/working/pifuhd/results/pifuhd_final/recon/result_%s_256.mp4' % file_name\nvideo_display_path = '/kaggle/working/pifuhd/results/pifuhd_final/result_%s_256_display.mp4' % file_name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:15.591010Z","iopub.execute_input":"2025-04-16T19:46:15.591699Z","iopub.status.idle":"2025-04-16T19:46:15.596602Z","shell.execute_reply.started":"2025-04-16T19:46:15.591672Z","shell.execute_reply":"2025-04-16T19:46:15.596067Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"%cd ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:18.051712Z","iopub.execute_input":"2025-04-16T19:46:18.052334Z","iopub.status.idle":"2025-04-16T19:46:18.057274Z","shell.execute_reply.started":"2025-04-16T19:46:18.052308Z","shell.execute_reply":"2025-04-16T19:46:18.056317Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:15:55.911313Z","iopub.execute_input":"2025-04-16T19:15:55.911813Z","iopub.status.idle":"2025-04-16T19:15:56.440564Z","shell.execute_reply.started":"2025-04-16T19:15:55.911788Z","shell.execute_reply":"2025-04-16T19:15:56.439664Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'lightweight-human-pose-estimation.pytorch'...\nremote: Enumerating objects: 124, done.\u001b[K\nremote: Counting objects: 100% (34/34), done.\u001b[K\nremote: Compressing objects: 100% (16/16), done.\u001b[K\nremote: Total 124 (delta 21), reused 19 (delta 18), pack-reused 90 (from 1)\u001b[K\nReceiving objects: 100% (124/124), 230.77 KiB | 7.96 MiB/s, done.\nResolving deltas: 100% (53/53), done.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"cd lightweight-human-pose-estimation.pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:20.344259Z","iopub.execute_input":"2025-04-16T19:46:20.344550Z","iopub.status.idle":"2025-04-16T19:46:20.349845Z","shell.execute_reply.started":"2025-04-16T19:46:20.344527Z","shell.execute_reply":"2025-04-16T19:46:20.349002Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/lightweight-human-pose-estimation.pytorch\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:16:34.283570Z","iopub.execute_input":"2025-04-16T19:16:34.284160Z","iopub.status.idle":"2025-04-16T19:16:36.436474Z","shell.execute_reply.started":"2025-04-16T19:16:34.284133Z","shell.execute_reply":"2025-04-16T19:16:36.435776Z"}},"outputs":[{"name":"stdout","text":"--2025-04-16 19:16:34--  https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\nResolving download.01.org (download.01.org)... 23.39.22.199, 2600:1405:1800:284::a87, 2600:1405:1800:287::a87\nConnecting to download.01.org (download.01.org)|23.39.22.199|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 87959810 (84M) [application/octet-stream]\nSaving to: ‘checkpoint_iter_370000.pth’\n\ncheckpoint_iter_370 100%[===================>]  83.88M  74.0MB/s    in 1.1s    \n\n2025-04-16 19:16:36 (74.0 MB/s) - ‘checkpoint_iter_370000.pth’ saved [87959810/87959810]\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch\nimport cv2\nimport numpy as np\nfrom models.with_mobilenet import PoseEstimationWithMobileNet\nfrom modules.keypoints import extract_keypoints, group_keypoints\nfrom modules.load_state import load_state\nfrom modules.pose import Pose, track_poses\nimport demo\n\ndef get_rect(net, images, height_size):\n    net = net.eval()\n\n    stride = 8\n    upsample_ratio = 4\n    num_keypoints = Pose.num_kpts\n    previous_poses = []\n    delay = 33\n    for image in images:\n        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n        img = cv2.imread(image, cv2.IMREAD_COLOR)\n        orig_img = img.copy()\n        orig_img = img.copy()\n        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n\n        total_keypoints_num = 0\n        all_keypoints_by_type = []\n        for kpt_idx in range(num_keypoints):  # 19th for bg\n            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n\n        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n        for kpt_id in range(all_keypoints.shape[0]):\n            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n        current_poses = []\n\n        rects = []\n        for n in range(len(pose_entries)):\n            if len(pose_entries[n]) == 0:\n                continue\n            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n            valid_keypoints = []\n            for kpt_id in range(num_keypoints):\n                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n            valid_keypoints = np.array(valid_keypoints)\n            \n            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n              pmin = valid_keypoints.min(0)\n              pmax = valid_keypoints.max(0)\n\n              center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int32)\n              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n              # if leg is missing, use pelvis to get cropping\n              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int32)\n              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n              center[1] += int(0.05*radius)\n            else:\n              center = np.array([img.shape[1]//2,img.shape[0]//2])\n              radius = max(img.shape[1]//2,img.shape[0]//2)\n\n            x1 = center[0] - radius\n            y1 = center[1] - radius\n\n            rects.append([x1, y1, 2*radius, 2*radius])\n\n        np.savetxt(rect_path, np.array(rects), fmt='%d')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:22.230912Z","iopub.execute_input":"2025-04-16T19:46:22.231185Z","iopub.status.idle":"2025-04-16T19:46:22.245541Z","shell.execute_reply.started":"2025-04-16T19:46:22.231165Z","shell.execute_reply":"2025-04-16T19:46:22.244785Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"net = PoseEstimationWithMobileNet()\ncheckpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\nload_state(net, checkpoint)\n\nget_rect(net.cuda(), [image_path], 512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:24.997047Z","iopub.execute_input":"2025-04-16T19:46:24.997589Z","iopub.status.idle":"2025-04-16T19:46:25.218196Z","shell.execute_reply.started":"2025-04-16T19:46:24.997564Z","shell.execute_reply":"2025-04-16T19:46:25.217470Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1979612249.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"%cd /kaggle/working/pifuhd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:28.266065Z","iopub.execute_input":"2025-04-16T19:46:28.266803Z","iopub.status.idle":"2025-04-16T19:46:28.271384Z","shell.execute_reply.started":"2025-04-16T19:46:28.266779Z","shell.execute_reply":"2025-04-16T19:46:28.270647Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/pifuhd\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"file_path = \"/kaggle/working/pifuhd/lib/sdf.py\"\n\n# Read file, replace deprecated np.bool\nwith open(file_path, \"r\") as f:\n    content = f.read()\n\ncontent = content.replace(\"np.bool\", \"bool\")\n\n# Write back the fixed version\nwith open(file_path, \"w\") as f:\n    f.write(content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:40:02.390706Z","iopub.execute_input":"2025-04-16T19:40:02.394170Z","iopub.status.idle":"2025-04-16T19:40:02.402738Z","shell.execute_reply.started":"2025-04-16T19:40:02.394130Z","shell.execute_reply":"2025-04-16T19:40:02.401288Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"!python -m apps.simple_test -r 256 --use_rect -i $image_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:46:30.984098Z","iopub.execute_input":"2025-04-16T19:46:30.984553Z","iopub.status.idle":"2025-04-16T19:47:02.085600Z","shell.execute_reply.started":"2025-04-16T19:46:30.984531Z","shell.execute_reply":"2025-04-16T19:47:02.084874Z"}},"outputs":[{"name":"stdout","text":"Resuming from  ./checkpoints/pifuhd.pt\n/kaggle/working/pifuhd/apps/recon.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(state_dict_path, map_location=cuda)\nWarning: opt is overwritten.\ntest data size:  4\ninitialize network with normal\ninitialize network with normal\ngenerate mesh (test) ...\n  0%|                                                     | 0/4 [00:00<?, ?it/s]./results/pifuhd_final/recon/result_female-1-casual-frame_0016_fake_B_256.obj\n[ WARN:0@12.057] global loadsave.cpp:848 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n 25%|███████████▎                                 | 1/4 [00:04<00:13,  4.35s/it]./results/pifuhd_final/recon/result_female-1-casual-frame_0016_real_B_256.obj\n 50%|██████████████████████▌                      | 2/4 [00:09<00:09,  4.59s/it]./results/pifuhd_final/recon/result_female-1-casual-frame_0075_fake_B_256.obj\n 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.83s/it]./results/pifuhd_final/recon/result_female-1-casual-frame_0075_real_B_256.obj\n100%|█████████████████████████████████████████████| 4/4 [00:18<00:00,  4.64s/it]\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"%ls /kaggle/working/pifuhd/results/pifuhd_final/recon","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T19:47:16.328776Z","iopub.execute_input":"2025-04-16T19:47:16.329483Z","iopub.status.idle":"2025-04-16T19:47:16.468579Z","shell.execute_reply.started":"2025-04-16T19:47:16.329452Z","shell.execute_reply":"2025-04-16T19:47:16.467863Z"}},"outputs":[{"name":"stdout","text":"result_female-1-casual-frame_0016_fake_B_256.obj\nresult_female-1-casual-frame_0016_fake_B_256.png\nresult_female-1-casual-frame_0016_real_B_256.obj\nresult_female-1-casual-frame_0016_real_B_256.png\nresult_female-1-casual-frame_0075_fake_B_256.obj\nresult_female-1-casual-frame_0075_fake_B_256.png\nresult_female-1-casual-frame_0075_real_B_256.obj\nresult_female-1-casual-frame_0075_real_B_256.png\n","output_type":"stream"}],"execution_count":89}]}